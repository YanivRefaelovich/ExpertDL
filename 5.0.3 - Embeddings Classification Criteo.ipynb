{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFM\n",
    "\n",
    "DeepFM can be seen as an improvement of WDL and FNN.Compared with WDL,DeepFM use FM instead of LR in the wide part and use concatenation of embedding vectors as the input of MLP in the deep part. Compared with FNN,the embedding vector of FM and input to MLP are same. And they do not need a FM pretrained vector to initialiaze,they are learned end2end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://deepctr-doc.readthedocs.io/en/latest/_images/DeepFM.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from deepctr.models import DeepFM\n",
    "from deepctr.utils import SingleFeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./criteo_sample.txt')\n",
    "\n",
    "sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "\n",
    "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "data[dense_features] = data[dense_features].fillna(0, )\n",
    "target = ['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding for sparse features,and do simple Transformation for dense features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python2.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "WARNING:root:\n",
      "DeepCTR version 0.4.0.post0 detected. Your version is 0.4.0.\n",
      "Use `pip install -U deepctr` to upgrade.Changelog: https://github.com/shenweichen/DeepCTR/releases/tag/v0.4.0.post0\n"
     ]
    }
   ],
   "source": [
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count unique features for each sparse field,and record dense feature field name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_feature_list = [SingleFeat(feat, data[feat].nunique())\n",
    "                       for feat in sparse_features]\n",
    "dense_feature_list = [SingleFeat(feat, 0,)\n",
    "                      for feat in dense_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate input data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train_model_input = [train[feat.name].values for feat in sparse_feature_list] + \\\n",
    "                    [train[feat.name].values for feat in dense_feature_list]\n",
    "test_model_input = [test[feat.name].values for feat in sparse_feature_list] + \\\n",
    "                   [test[feat.name].values for feat in dense_feature_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model, train, predict and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From deepctr/layers/interaction.py:424: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From deepctr/layers/interaction.py:424: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = DeepFM({\"sparse\": sparse_feature_list,\n",
    "                \"dense\": dense_feature_list}, task='binary')\n",
    "model.compile(\"adam\", \"binary_crossentropy\",\n",
    "              metrics=['binary_crossentropy'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128 samples, validate on 32 samples\n",
      "WARNING:tensorflow:From /home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss: 1.2060 - binary_crossentropy: 1.2059 - val_loss: 1.1693 - val_binary_crossentropy: 1.1693\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.1176 - binary_crossentropy: 1.1176 - val_loss: 1.1102 - val_binary_crossentropy: 1.1102\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.0356 - binary_crossentropy: 1.0356 - val_loss: 1.0544 - val_binary_crossentropy: 1.0544\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.9595 - binary_crossentropy: 0.9594 - val_loss: 1.0014 - val_binary_crossentropy: 1.0013\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.8882 - binary_crossentropy: 0.8882 - val_loss: 0.9509 - val_binary_crossentropy: 0.9508\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.8216 - binary_crossentropy: 0.8216 - val_loss: 0.9019 - val_binary_crossentropy: 0.9019\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.7589 - binary_crossentropy: 0.7588 - val_loss: 0.8541 - val_binary_crossentropy: 0.8541\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.6998 - binary_crossentropy: 0.6997 - val_loss: 0.8083 - val_binary_crossentropy: 0.8082\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.6444 - binary_crossentropy: 0.6444 - val_loss: 0.7640 - val_binary_crossentropy: 0.7639\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.5927 - binary_crossentropy: 0.5927 - val_loss: 0.7213 - val_binary_crossentropy: 0.7212\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train[target].values,\n",
    "                    batch_size=256, epochs=10, verbose=2, validation_split=0.2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ans = model.predict(test_model_input, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test LogLoss', 1.0549)\n",
      "('test AUC', 0.2857)\n"
     ]
    }
   ],
   "source": [
    "print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And Now with hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from deepctr.models import DeepFM\n",
    "from deepctr.utils import SingleFeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./criteo_sample.txt')\n",
    "\n",
    "sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "\n",
    "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "data[dense_features] = data[dense_features].fillna(0, )\n",
    "target = ['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do simple Transformation for dense features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set hashing space for each sparse field,and record dense feature field name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_feature_list = [SingleFeat(feat, 1000, hash_flag=True, dtype='string')  # since the input is string\n",
    "                           for feat in sparse_features]\n",
    "dense_feature_list = [SingleFeat(feat, 0, ) for feat in dense_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate input data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train_model_input = [train[feat.name].values for feat in sparse_feature_list] + \\\n",
    "                    [train[feat.name].values for feat in dense_feature_list]\n",
    "test_model_input = [test[feat.name].values for feat in sparse_feature_list] + \\\n",
    "                   [test[feat.name].values for feat in dense_feature_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model, train, predict and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = DeepFM({\"sparse\": sparse_feature_list,\n",
    "                \"dense\": dense_feature_list}, task='binary')\n",
    "model.compile(\"adam\", \"binary_crossentropy\",\n",
    "              metrics=['binary_crossentropy'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128 samples, validate on 32 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.8388 - binary_crossentropy: 0.8388 - val_loss: 0.7626 - val_binary_crossentropy: 0.7626\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.7905 - binary_crossentropy: 0.7904 - val_loss: 0.7425 - val_binary_crossentropy: 0.7425\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.7466 - binary_crossentropy: 0.7466 - val_loss: 0.7241 - val_binary_crossentropy: 0.7240\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.7066 - binary_crossentropy: 0.7066 - val_loss: 0.7070 - val_binary_crossentropy: 0.7070\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.6697 - binary_crossentropy: 0.6697 - val_loss: 0.6911 - val_binary_crossentropy: 0.6910\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.6352 - binary_crossentropy: 0.6352 - val_loss: 0.6760 - val_binary_crossentropy: 0.6759\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.6027 - binary_crossentropy: 0.6026 - val_loss: 0.6616 - val_binary_crossentropy: 0.6615\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.5718 - binary_crossentropy: 0.5718 - val_loss: 0.6478 - val_binary_crossentropy: 0.6478\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.5425 - binary_crossentropy: 0.5424 - val_loss: 0.6348 - val_binary_crossentropy: 0.6347\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.5144 - binary_crossentropy: 0.5143 - val_loss: 0.6224 - val_binary_crossentropy: 0.6223\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train[target].values,\n",
    "                    batch_size=256, epochs=10, verbose=2, validation_split=0.2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ans = model.predict(test_model_input, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test LogLoss', 0.6435)\n",
      "('test AUC', 0.528)\n"
     ]
    }
   ],
   "source": [
    "print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
